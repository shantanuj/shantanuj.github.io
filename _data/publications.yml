# Papers list on home page
papers:
  - title: "TDAM: Top-Down Attention Module for Contextually-Guided Feature Selection in CNNs"
    authors: "Shantanu Jaiswal, Basura Fernando, Cheston Tan"
    venue: "In *European Conference on Computer Vision (ECCV)*, 2022."
    teaser: tdam_teaser.png
    links:
      - "[[Paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850255.pdf)"
      - "[[Suppl.]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850255-supp.pdf)"
      - "[[Code]](https://github.com/shantanuj/TDAM_Top_down_attention_module)"
    descript: "<ol><li>Introduces top-down attention to enable models to <i><b>'look again' and attend to salient objects or features</b></i> (at multiple levels of the hierarchy) based on task or contextual information. </li>
               <li>Also, makes models <i><b>more robust to changes in input resolution</b></i> and <i><b>reduces entropy of output activations </b></i>(indicating enhanced feature selectivity; entropy and feature co-activation analysis in supplemental).</li></ol>"
    
  - title: "A Probabilistic-Logic based Commonsense Representation Framework for Modelling Inferences with Multiple Antecedents and Varying Likelihoods"
    authors: "Shantanu Jaiswal, Liu Yan, Dongkyu Choi, Kenneth Kwok"
    venue: "*arXiv preprint*, 2022."
    teaser: pckr_teaser_2.png
    links:
      - "[[Paper]](https://arxiv.org/abs/2211.16822)"
      - "[Code & data pending agency approval]"
    descript: "<ol><li>Introduces a probabilistic-logic based representation scheme to represent world knowledge with <i><b>different 'certainty levels'</b></i> and perform <i><b>context-dependent non-monotonic inferences</b></i> (wherein likelihoods and/or inferences can change with newly provided contextual/situational knowledge). </li>
                  <li>Also, introduces a <b>hierarchical conceptual ontology</b> to structure knowledge and incrementally increase semantic coverage through concept-specific relations.</li></ol>"
  
  - title: "What do CNNs gain by imitating the visual development of primate infants?"
    authors: "Shantanu Jaiswal, Dongkyu Choi, Basura Fernando"
    venue: "In *British Machine Vision Conference (BMVC)*, 2020."
    teaser: grow_cnns_3.png
    links:
      - "[[Paper]](https://www.bmvc2020-conference.com/assets/papers/0196.pdf)"
      - "[[Suppl.]](https://shantanuj.github.io/files/bmvc_supplemental.pdf)"
      - "[[Code]](https://github.com/shantanuj/Imitating-primate-infant-visual-development-CNNs)"
      - "[[Abstract (Cogsci 2020)]](https://www.cognitivesciencesociety.org/cogsci20/papers/0860/0860.pdf)"
    descript: "<ol><li>Analyses a <i><b>growth-based training strategy</b></i> wherein models are grown and inputs are gradually refined over course of training. </li>
                   <li>Growth-based training potentially allows <i><b>'coarse global' patterns</b></i> to be identified first and then <i><b>'finer' ones</b></i> later in a more hierarchical manner; visualization of induced filters during training in supplemental.</li></ol>"
    
techprojects:
  - title: "Domain adaptation techniques for aspect-based sentiment analysis"
    authors: "Shantanu Jaiswal (Final year undergraduate project)"
    teaser: da_fgs.png
    links:
      - "[[Report]](https://dr.ntu.edu.sg/handle/10356/74089)"
      - "[[Code]](https://github.com/shantanuj/Fine_Grained_Sen_Extraction)"
      
  - title: "FakeNet: A Framework to Detect and Analyze Fake News"
    authors: "Shantanu Jaiswal, Abhay Nainan, Jacob Sunny, Sharique Zaman"
    teaser: stance_project.png
    links:
      - "[[Report]](https://shantanuj.github.io/files/FakeNet_report.pdf)"
      - "[[Code]](https://github.com/shantanuj/Fake_Net)"